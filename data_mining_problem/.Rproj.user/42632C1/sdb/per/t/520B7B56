{
    "collab_server" : "",
    "contents" : "#PART I Data manipulation\n############################################################################\n#install.packages(\"magrittr\")\n#install.packages(\"glmnet\")\n#install.packages(\"caret\")\n#install.packages(\"e1071\")\n#install.packages(\"pROC\")\n#install.packages(\"ROSE\")\n\nlibrary(magrittr)\nlibrary(glmnet)\nlibrary(caret)\nlibrary(magrittr)\nlibrary(e1071)\nlibrary(pROC)\n\npath <- getwd()\nsetwd(\"/Users/weijuanliang/Desktop/数据之星/3月17日\")\n\ndata_row<-read.csv(file=\"test-2.csv\",header=T,sep=\",\",fileEncoding=\"gbk\",stringsAsFactors = F)\nView(data_row)\ndim(data_row)\n#transform the Inf to NA\ndata_row[sapply(data_row,is.infinite)] <- NA\n\n#NA_Index <- vector() \n#for(i in 1:nrow(data_row)){\n#  NA_Index[i] = length(which(lapply(data_row[i,], is.na) == TRUE))\n#}\n\n#NA_Index <- which(NA_Index != 0)\n\n#NA_data <- data_row[NA_Index,]\n#View(NA_data)\nIndex <- which(is.na(data_row))\nView(data_row)\n\n\ndata_1<-data[which(data$industry_name!=\"金融业\"),]#delete the financial industry\ndata_1 <-data_1[,-c(1,62)]#delete irrelevant information including the coding for sample and Industry name\n#View(data_1)\n\ndata_1_no<-data_1[which(data_1$default==0),]\ndata_1_yes<-data_1[which(data_1$default!=0),]\n\n(n<-dim(data_1)[1])\n(n1<-dim(data_1_no)[1])\n(n2<-dim(data_1_yes)[1])\n\n#小类平衡法\n#Sample the data\nset.seed(100)\nM = 1/(n2/n1) # 不平衡比例\nsample_yes_index = sample(n2, floor(n*1.3) , replace = T)\n\ndata_balance_yes = data_1_yes[sample_yes_index,]\ndata_balance_no = data_1_no\n#View(data_balance_no)\n#View(data_balance_yes)\nnrow(data_balance_yes)\nnrow(data_balance_no)\n\ndata_balance_total <- rbind(data_balance_no, data_balance_yes)\n#View(data_balance_total)\n#nrow(data_balance_total)\n\n#depart the data into training sample and testing sample\nn_balance <- nrow(data_balance_total)\nsample_index <- sample(n_balance, floor(0.75*n_balance), replace = F)\ndata_tra <- data_balance_total[sample_index,]\ndata_test <- data_balance_total[-sample_index,]\n\nnc <- ncol(data_tra)\nnr <- length(sample_index)\nx_tra <- data_tra[,2:nc] %>% unlist %>% as.numeric %>% matrix(nrow=nr,ncol=(nc-1))\ny_tra <- data_tra[,1] %>% unlist %>% as.numeric \n\nx_test <- data_test[,2:nc] %>% unlist %>% as.numeric %>% matrix(nrow = (n_balance-nr),ncol = (nc-1))\ny_test <- data_test[,1] %>% unlist %>% as.numeric\ntable(y_tra)\ntable(y_test)\n\n\n\n\n\n\n\n\n# #PART II:  Construct the model \n# ############################################################################\n\n\n#Choose the best tuning parameter\ncv_fit <- cv.glmnet(x_tra, y_tra,  family = \"binomial\",nfolds=5, type.measure=\"class\")# k-fold cv for glmnet\nplot(cv_fit)\nlambda_min <- cv_fit$lambda.min  #the value of lambda that gives minmum cvm\nlambda_lse <- cv_fit$lambda.1se  #largest value of lambda such that error is within 1 standard error of the minimum.\n\n#fit the model using penalizated GLM\nfit_1 <- glmnet(x_tra, y_tra,family=\"binomial\")\nplot(fit_1, xvar = \"lambda\")\ngrid()\n\n\n#Choose important variable by regularization\ncoef_1 <- coef.glmnet(fit_1, s = cv_fit$lambda.1se)    # extract coefficients at lambda equals to lambda.lse\n\n#PART III:  Model evaluation \n############################################################################\npred_1 <-predict(fit_1, newx=x_test, s=cv_fit$lambda.1se, type = \"class\") %>% as.numeric\ntable(pred_1)\ntable(y_test)\n#Confusion Matrix\nconfusionMatrix(pred_1 %>% as.factor ,y_test %>% as.factor)\nlibrary(ROSE)\naccuracy.meas(y_test,pred_1)#计算准确率，召回率和F测度\nroc.curve(y_test ,pred_1,plotit = F)# 0.5分类效果很差\n\n\n\n\n############################################################\n#adaboost\n############################################################\n#install.packages(\"adabag\")\ntrain <- cbind(y_tra, x_tra) %>% as.data.frame\nnames(train) <- names(data_1_no)\ntrain$default <- as.factor(train$default)\n\n\ntest <- cbind(y_test, x_test) %>% as.data.frame\nnames(test) <- names(data_1_no)\ntest$default <- as.factor(test$default)\n\nlibrary(adabag)\n#训练样本\nboosting_row <- boosting(default~., data = train)\n#预测结果\nboosting_matrix_pred <- table(train$default, predict(boosting_row, train)$class)\nboosting_matrix_pred <- table(test$default,predict(boosting_row,test)$class)\n#计算误差???\n(E_boosting=(sum(boosting_matrix_pred)-sum(diag(boosting_matrix_pred)))/sum(boosting_matrix_pred))\n#0.001152074\n#画出变量重要性图\nbarplot(boosting_row$importance)\n#计算全体的误差演???\nb <- errorevol(boosting_row, train)\nplot(b$error, type = \"l\",main = \"AdaBoost error vs number of trees\")#对误差演变进行画???\n\n############################################################\n#bagging()\n############################################################\nbagging_row <- bagging(default~., data = train)##建立bagging分类模型\n(bagging_matrix_pred <- table(train$default, predict(bagging_row, train)$class))\n#计算误差???\n(E_bagging=(sum(bagging_matrix_pred)-sum(diag(bagging_matrix_pred)))/sum(bagging_matrix_pred))\n#画出变量重要性图\nbarplot(bagging_row$importance)\n\n\nsetwd(path)\n\n\n\n",
    "created" : 1525335832348.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2457195310",
    "id" : "520B7B56",
    "lastKnownWriteTime" : 1525335509,
    "last_content_update" : 1525335509,
    "path" : "C:/Users/heyouxin/Desktop/信用评级_比赛/数据之星【20180411】.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 16,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}